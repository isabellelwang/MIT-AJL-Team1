{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Proccesing of the data\n",
    "\n",
    "## Looking at the data \n",
    "\n",
    "I will styart by just exploring the data and trying to get familiar to it and see what I am working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: None not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# numpy compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     from pandas.compat import (\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mis_numpy_dev\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_is_numpy_dev\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport] # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompressors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_numpy_dev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m from pandas.compat.pyarrow import (\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_nlv\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_min_numpy_ver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;34mf\"this version of pandas is incompatible with numpy < {_min_numpy_ver}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: this version of pandas is incompatible with numpy < 1.22.4\nyour numpy version is 1.19.5.\nPlease upgrade numpy to >= 1.22.4 to use this pandas version",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/cx/8cgxj_qx5wzc8zcq_tbs6sc80000gn/T/ipykernel_59575/25688022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageEnhance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_err\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0m_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     raise ImportError(\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;34mf\"C extension: {_module} not built. If you want to import \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: C extension: None not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image, ImageEnhance\n",
    "import random\n",
    "import hashlib\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = \"/Users/michelangelozampieri/Downloads/bttai-ajl-2025/train/train\"\n",
    "categories = os.listdir(data_path)\n",
    "# Remove .DS_Store from the list\n",
    "categories.remove('.DS_Store')\n",
    "for c in categories:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of each category and store results in a dataframe\n",
    "image_counts = {category: len(os.listdir(os.path.join(data_path, category))) for category in categories}\n",
    "df = pd.DataFrame(image_counts.items(), columns=['Category', 'Image Count'])    \n",
    "print(df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an image\n",
    "img = Image.open('/Users/michelangelozampieri/Downloads/bttai-ajl-2025/train/train/acne/0cff6f3c9bb267f68c77740fc9c58587.jpg')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display a few random images for each label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random images from each category\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))  # Adjust as needed\n",
    "for i, category in enumerate(random.sample(categories, min(10, len(categories)))):\n",
    "    image_path = os.path.join(data_path, category, random.choice(os.listdir(os.path.join(data_path, category))))\n",
    "    img = Image.open(image_path)\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(category)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation\n",
    "\n",
    "I will perform some image augemntation which will take existing images and flip, rotate, and slightly change the existing images to create more images to get a better training set for the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_UD(image_path):\n",
    "    \"\"\"Flip an image upside down and return the result\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    return img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "def flip_LR(image_path):\n",
    "    \"\"\"Flip an image left to right and return the result\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "\n",
    "def rotate(image_path, degrees):\n",
    "    \"\"\"Rotate an image and return the result\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    return img.rotate(degrees)\n",
    "\n",
    "def adjust_brightness(image_path, factor=0.5):\n",
    "    \"\"\"Adjust the brightness and return the result\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    enhancer = ImageEnhance.Brightness(img)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def adjust_contrast(image_path, factor=1.5):\n",
    "    \"\"\"Adjust the contrast and return the result\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    enhancer = ImageEnhance.Contrast(img)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def adjust_saturation(image_path, factor=1.5):\n",
    "    \"\"\"ADjust the saturation and return the result\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    enhancer = ImageEnhance.Color(img)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def adjust_hue(image_path, factor=0.1):\n",
    "    \"\"\"Adjust the hue of an image and return the result\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")  # Ensure RGB mode\n",
    "    img = np.array(img)  # Convert to NumPy array\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV) # Convert from RGB to HSV\n",
    "\n",
    "    hsv[..., 0] = (hsv[..., 0].astype(np.int16) + int(factor * 180)) % 180  # Adjust hue\n",
    "    adjusted_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB) # Convert back to RGB\n",
    "    return Image.fromarray(adjusted_img)\n",
    "\n",
    "def save_image(img, original_path, output_dir, suffix):\n",
    "    \"\"\"Save the image to the output directory with a suffix\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    base_name = os.path.basename(original_path)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    new_name = f\"{name}_{suffix}{ext}\"\n",
    "    img.save(os.path.join(output_dir, new_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(category, data_path):\n",
    "    \"\"\"Augment all images in a given directory and save them to a directory within the given directory\"\"\"\n",
    "    category_dir = os.path.join(data_path, category)\n",
    "    \n",
    "    # Create a new directory within the category directory to store augmented images\n",
    "    augmented_dir = os.path.join(category_dir, 'augmented')\n",
    "    os.makedirs(augmented_dir, exist_ok=True)\n",
    "    \n",
    "    # For every file in the directory\n",
    "    image_files = [f for f in os.listdir(category_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    for file in tqdm(image_files, desc=\"Augmenting images\"):\n",
    "        file_path = os.path.join(category_dir, file)\n",
    "        save_image(flip_UD(file_path), file_path, augmented_dir, \"flip_Up_Down\")\n",
    "        save_image(flip_LR(file_path), file_path, augmented_dir, \"flip_Left_Right\")\n",
    "        save_image(rotate(file_path, 90), file_path, augmented_dir, \"rotate_90\")\n",
    "        save_image(rotate(file_path, 180), file_path, augmented_dir, \"rotate_180\")\n",
    "        save_image(rotate(file_path, 270), file_path, augmented_dir, \"rotate_270\")\n",
    "        save_image(adjust_brightness(image_path, factor=0.5), file_path, augmented_dir, \"adjusted_brightness\")\n",
    "        save_image(adjust_contrast(image_path, factor=1.5), file_path, augmented_dir, \"adjusted_contrast\")\n",
    "        save_image(adjust_saturation(image_path, factor=1.5), file_path, augmented_dir, \"adjusted_saturation\")\n",
    "        save_image(adjust_hue(image_path, factor=0.1), file_path, augmented_dir, \"adjusted_hue\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment('acne', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment every other category except acne\n",
    "for category in categories:\n",
    "    if category != 'acne':\n",
    "        augment(category, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the images and stores results in a new dataframe. \n",
    "def count_images(directory):\n",
    "    \"\"\"Count the number of images in a directory\"\"\"\n",
    "    return len([f for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_counts_dataframe(base_dir):\n",
    "    \"\"\"Create a DataFrame with counts of original and augmented images for each category\"\"\"\n",
    "    data = []\n",
    "    subdirs = [subdir for subdir in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, subdir))]\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        input_dir = os.path.join(base_dir, subdir)\n",
    "        original_count = count_images(input_dir)\n",
    "        \n",
    "        augmented_dir = os.path.join(input_dir, \"augmented\")\n",
    "        if os.path.exists(augmented_dir):\n",
    "            augmented_count = count_images(augmented_dir)\n",
    "        else:\n",
    "            augmented_count = 0\n",
    "        \n",
    "        total_count = original_count + augmented_count\n",
    "        data.append([subdir, original_count, augmented_count, total_count])\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=[\"Category\", \"Original Images\", \"Augmented Images\", \"Total Images\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_image_counts_dataframe(data_path)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that for each row the number of original images * 3 is equal to the number of augmented images and store true or false in a new cell\n",
    "df[\"Augmented Correct\"] = df[\"Original Images\"] * 9 == df[\"Augmented Images\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'Augmented Correct' column exists\n",
    "if \"Augmented Correct\" not in df.columns:\n",
    "\tdf[\"Augmented Correct\"] = df[\"Original Images\"] * 9 == df[\"Augmented Images\"]\n",
    "\n",
    "# Count the trues in Augmented Correct\n",
    "correct_augmented = df[\"Augmented Correct\"].sum()\n",
    "print(f\"Correctly augmented {correct_augmented} categories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total number of original and total images \n",
    "total_original_images = df[\"Original Images\"].sum()\n",
    "total_augmented_images = df[\"Augmented Images\"].sum()\n",
    "total_images = df[\"Total Images\"].sum()\n",
    "\n",
    "print(f\"Total original images: {total_original_images}\")\n",
    "print(f\"Total augmented images: {total_augmented_images}\")\n",
    "print(f\"Total images: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all images to be 224 x 224, this will make it easier to train the CNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize every image in every durectory and sub directory to be 244 x 244 pixels\n",
    "def resize_images(directory, size):\n",
    "    \"\"\"Resize all images in a directory to the given size\"\"\"\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    for file in tqdm(image_files, desc=f\"Resizing images in {os.path.basename(directory)}\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        img = Image.open(file_path)\n",
    "        img = img.resize((size, size))\n",
    "        img.save(file_path)\n",
    "\n",
    "def resize_all_images(base_dir, size):\n",
    "    \"\"\"Resize all images in a directory and subdirectories to the given size\"\"\"\n",
    "    subdirs = [subdir for subdir in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, subdir))]\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        resize_images(subdir_path, size)\n",
    "        augmented_dir = os.path.join(subdir_path, \"augmented\")\n",
    "        if os.path.exists(augmented_dir):\n",
    "            resize_images(augmented_dir, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_all_images(data_path, 244)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the resizing worked and that all images are 244 x 244"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many pictures in each directory are 244 x 244 pixels\n",
    "def check_image_sizes(directory):\n",
    "    \"\"\"Check the size of all images in a directory and return the count of correctly sized images\"\"\"\n",
    "    correct_size_count = 0\n",
    "    image_files = [f for f in os.listdir(directory) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    for file in tqdm(image_files, desc=f\"Checking image sizes in {os.path.basename(directory)}\"):\n",
    "        file_path = os.path.join(directory, file)\n",
    "        img = Image.open(file_path)\n",
    "        if img.size == (244, 244):\n",
    "            correct_size_count += 1\n",
    "    return correct_size_count\n",
    "\n",
    "def check_all_image_sizes(base_dir):\n",
    "    \"\"\"Check the size of all images in a directory and subdirectories and update the dataframe\"\"\"\n",
    "    correct_sizes = []\n",
    "    subdirs = [subdir for subdir in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, subdir))]\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        correct_size_count = check_image_sizes(subdir_path)\n",
    "        augmented_dir = os.path.join(subdir_path, \"augmented\")\n",
    "        if os.path.exists(augmented_dir):\n",
    "            correct_size_count += check_image_sizes(augmented_dir)\n",
    "        correct_sizes.append(correct_size_count)\n",
    "    \n",
    "    df[\"Correct Size Images\"] = correct_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_all_image_sizes(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"All Correct Size\"] = df[\"Total Images\"] == df[\"Correct Size Images\"]\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_correct_size = df[\"All Correct Size\"].sum()\n",
    "print(f\"All images are the correct size: {all_correct_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_img_count = df[\"Total Images\"].sum()\n",
    "print(f\"Total images: {total_img_count}\")\n",
    "\n",
    "total_aug_count = df[\"Augmented Images\"].sum()\n",
    "print(f\"Total augmented images: {total_aug_count}\")\n",
    "\n",
    "total_original_count = df[\"Original Images\"].sum()\n",
    "print(f\"Total original images: {total_original_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a data set of 17160 images. From the original 2860, we increased the number of total images by 14300 images. We can start training a CNN using these as the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the sizes of 100 random images\n",
    "\n",
    "def check_random_image_sizes(base_dir, num_images):\n",
    "    \"\"\"Check the size of a random sample of images in a directory and subdirectories\"\"\"\n",
    "    subdirs = [subdir for subdir in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, subdir))]\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(base_dir, subdir)\n",
    "        image_files = [f for f in os.listdir(subdir_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        random_files = random.sample(image_files, min(num_images, len(image_files)))\n",
    "        for file in random_files:\n",
    "            file_path = os.path.join(subdir_path, file)\n",
    "            img = Image.open(file_path)\n",
    "            print(f\"Image size for {file}: {img.size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_random_image_sizes(data_path, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
