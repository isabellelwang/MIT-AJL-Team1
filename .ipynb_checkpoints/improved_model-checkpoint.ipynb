{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB3 # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # type: ignore\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Reshape, Multiply # type: ignore\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.optimizers import Adam # type: ignore\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setting up data augmentation and loading dataset...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSetting up data augmentation and loading dataset...\")\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values\n",
    "    rotation_range=30, # Randomly rotate images in the range (degrees, 0 to 180)\n",
    "    horizontal_flip=True, # Randomly flip images\n",
    "    vertical_flip=True, # Randomly flip images\n",
    "    fill_mode=\"nearest\" # Fill in missing pixels with the nearest filled value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataset directory paths\n",
    "train_dir = \"/Users/michelangelozampieri/Desktop/AJL_MIT/bttai-ajl-2025-no-augm/train/train\"\n",
    "test_dir = \"/Users/michelangelozampieri/Desktop/AJL_MIT/bttai-ajl-2025-no-augm/test/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data from: /Users/michelangelozampieri/Desktop/AJL_MIT/bttai-ajl-2025-no-augm/train/train\n",
      "Found 2860 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(f\"Loading training data from: {train_dir}\")\n",
    "train_generator = datagen.flow_from_directory( # Load images from directory\n",
    "    directory=train_dir, # Load from training directory\n",
    "    target_size=(224, 224), # Resize images to 224x224\n",
    "    batch_size=8, # Set batch size\n",
    "    class_mode=\"categorical\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1227 validated image filenames.\n",
      "✅ Test dataset loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with filenames (no labels)\n",
    "test_files = os.listdir(test_dir)\n",
    "df_test = pd.DataFrame({\"filename\": test_files})  # No \"label\" column since it's unlabeled\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Normalize pixel values\n",
    "\n",
    "# Load test images without labels\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    directory=test_dir,\n",
    "    x_col=\"filename\",\n",
    "    y_col=None,  # No labels\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,  # No labels\n",
    "    shuffle=False  # Keep order for predictions\n",
    ")\n",
    "\n",
    "print(\"✅ Test dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 21\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the SE block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Squeeze-and-Excitation block...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefining Squeeze-and-Excitation block...\")\n",
    "def se_block(input_tensor, ratio=16):\n",
    "    \"\"\"Squeeze-and-Excitation block to improve attention on important features.\"\"\"\n",
    "    channels = input_tensor.shape[-1]\n",
    "    x = GlobalAveragePooling2D()(input_tensor)\n",
    "    x = Reshape((1, 1, channels))(x)\n",
    "    x = Dense(channels // ratio, activation=\"relu\")(x)\n",
    "    x = Dense(channels, activation=\"sigmoid\")(x)\n",
    "    return Multiply()([input_tensor, x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load pretrained EfficientNetB3 model with SE block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading EfficientNetB3 model with Squeeze-and-Excitation block...\n",
      "Base model loaded successfully.\n",
      "\n",
      "Adding Squeeze-and-Excitation block to the model...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading EfficientNetB3 model with Squeeze-and-Excitation block...\")\n",
    "base_model = EfficientNetB3(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze base model initially\n",
    "print(\"Base model loaded successfully.\")\n",
    "\n",
    "# Add SE Block to the output of EfficientNet\n",
    "print(\"\\nAdding Squeeze-and-Excitation block to the model...\")\n",
    "x = base_model.output\n",
    "x = se_block(x)  # Applying Squeeze-and-Excitation\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "output = Dense(num_classes, activation=\"softmax\")(x)  # Final output layer\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing class weights...\n",
      "Class weights: {0: 1.0639880952380953, 1: 0.582010582010582, 2: 1.1163153786104605, 3: 0.4152148664343786, 4: 3.1672203765227023, 5: 2.4761904761904763, 6: 1.2848158131176999, 7: 2.348111658456486, 8: 0.9523809523809523, 9: 2.1279761904761907, 10: 0.5698346284120342, 11: 1.2494539100043687, 12: 1.2494539100043687, 13: 1.746031746031746, 14: 0.7524335701131282, 15: 1.072365954255718, 16: 1.1444577831132452, 17: 1.723930078360458, 18: 2.8373015873015874, 19: 0.33462033462033464, 20: 1.6408491107286287}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing class weights...\")\n",
    "y_train = train_generator.classes  # Get class labels\n",
    "class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining Focal loss function...\n",
      "\n",
      "Compiling model...\n",
      "Model compiled successfully.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefining Focal loss function...\")\n",
    "import tensorflow.keras.backend as K # type: ignore\n",
    "\n",
    "def focal_loss(alpha=0.25, gamma=2.0):\n",
    "    \"\"\"Focal loss to address class imbalance.\"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0 - epsilon)\n",
    "        pt = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        return -K.mean(alpha * K.pow(1 - pt, gamma) * K.log(pt))\n",
    "    return loss\n",
    "\n",
    "print(\"\\nCompiling model...\")\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss=focal_loss(), metrics=[\"accuracy\"])\n",
    "print(\"Model compiled successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train with class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m162/358\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m18:18\u001b[0m 6s/step - accuracy: 0.1141 - loss: 0.0315"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 22:26:46.936614: W tensorflow/core/framework/op_kernel.cc:1829] UNKNOWN: OSError: [Errno 89] Operation canceled\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n",
      "    ret = func(*args)\n",
      "          ^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n",
      "    values = next(generator_state.get_iterator(iterator_id))\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 247, in _finite_generator\n",
      "    yield self.py_dataset[i]\n",
      "          ~~~~~~~~~~~~~~~^^^\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n",
      "    return self._get_batches_of_transformed_samples(index_array)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n",
      "    img = image_utils.load_img(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n",
      "    img = pil_image.open(io.BytesIO(f.read()))\n",
      "                                    ^^^^^^^^\n",
      "\n",
      "OSError: [Errno 89] Operation canceled\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nOSError: [Errno 89] Operation canceled\nTraceback (most recent call last):\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 247, in _finite_generator\n    yield self.py_dataset[i]\n          ~~~~~~~~~~~~~~~^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n                                    ^^^^^^^^\n\nOSError: [Errno 89] Operation canceled\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_100112]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_generator, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel trained successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node PyFunc defined at (most recent call last):\n<stack traces unavailable>\nOSError: [Errno 89] Operation canceled\nTraceback (most recent call last):\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/ops/script_ops.py\", line 269, in __call__\n    ret = func(*args)\n          ^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/autograph/impl/api.py\", line 643, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 198, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py\", line 247, in _finite_generator\n    yield self.py_dataset[i]\n          ~~~~~~~~~~~~~~~^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 68, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/legacy/preprocessing/image.py\", line 313, in _get_batches_of_transformed_samples\n    img = image_utils.load_img(\n          ^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/image_utils.py\", line 236, in load_img\n    img = pil_image.open(io.BytesIO(f.read()))\n                                    ^^^^^^^^\n\nOSError: [Errno 89] Operation canceled\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_one_step_on_iterator_100112]"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining model...\")\n",
    "history = model.fit(train_generator, epochs=20)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"improved_model.h5\")\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine Tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFine-tuning model...\")\n",
    "for layer in base_model.layers[-50:]:  # Unfreeze last 50 layers for fine-tuning\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile again with lower learning rate\n",
    "print(\"\\nCompiling model for fine-tuning...\")\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss=focal_loss(), metrics=[\"accuracy\"])\n",
    "print(\"Model compiled successfully.\")\n",
    "\n",
    "# Train again with fine-tuning\n",
    "print(\"\\nTraining model with fine-tuning...\")\n",
    "history = model.fit(train_generator, epochs=10, validation_data=test_generator, class_weight=class_weight_dict)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"improved_model_with_params.h5\")\n",
    "print(\"Model saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
